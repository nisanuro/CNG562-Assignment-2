{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562-Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisanuro/CNG562-Assignment-2/blob/naive/CNG562_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "738YGK5FqWmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics, datasets, preprocessing\n",
        "%matplotlib inline\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, ComplementNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skeQ9JV9_rlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomOneHoldout(X_train, Y_train):\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjpybV6_v7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratifiedOneHoldout(X_train, Y_train):\n",
        "  \n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k95XLXS5OIZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NaiveBayes(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "    gaussian = GaussianNB()\n",
        "    categorical = CategoricalNB()\n",
        "    bernoulli = BernoulliNB()\n",
        "    complement = ComplementNB()\n",
        "    multinomial = MultinomialNB()\n",
        "\n",
        "    models = [gaussian, categorical, bernoulli, complement, multinomial]\n",
        "\n",
        "    # 5-Fold\n",
        "    print(\"\\n5-Fold\")\n",
        "    for i in models:\n",
        "        cv = cross_val_score(i, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "        print(str(i).split('N')[0] + \" Naive Bayes Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    # 10-Fold\n",
        "    print(\"\\n10-Fold\")\n",
        "    for i in models:\n",
        "        cv = cross_val_score(i, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "        print(str(i).split('N')[0] + \" Naive Bayes Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    # Random One Holdout\n",
        "    x_train, x_test, y_train, y_test = randomOneHoldout(X_train, Y_train)\n",
        "\n",
        "    print(\"\\nRandom One Holdout\")\n",
        "    for i in models:\n",
        "        i.fit(x_train, y_train)\n",
        "        y_pred = i.predict(x_test)\n",
        "        print(str(i).split('N')[0] + \" Naive Bayes Accuracy: \", metrics.accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "\n",
        "    # Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test = stratifiedOneHoldout(X_train, Y_train)\n",
        "    \n",
        "    print(\"\\nStratified One Holdout\")\n",
        "    for i in models:\n",
        "        i.fit(x_train, y_train)\n",
        "        y_pred = i.predict(x_test)\n",
        "        print(str(i).split('N')[0] + \" Naive Bayes Accuracy: \", metrics.accuracy_score(y_test, y_pred)*100)                  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrILGyKFSiP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTree(X, Y):\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "    \n",
        "    # 5-Fold\n",
        "    print(\"\\n5-Fold: \")\n",
        "    tuningDepth(X_train, Y_train, 0)\n",
        "\n",
        "    # 10-Fold\n",
        "    print(\"\\n10-Fold: \")\n",
        "    tuningDepth(X_train, Y_train, 1)\n",
        "\n",
        "    # Random One Holdout\n",
        "    print(\"\\nRandom One Holdout: \")   \n",
        "    tuningDepth(X_train, Y_train, 2)\n",
        "  \n",
        "    # Stratified One Holdout\n",
        "    print(\"\\nStratified One Holdout: \")\n",
        "    tuningDepth(X_train, Y_train, 3)\n",
        "    \n",
        "    #\n",
        "    #   Continue with 5-Fold, Depth = 5\n",
        "    #\n",
        "    \n",
        "    print(\"5-Fold, Depth=5\\n\")\n",
        "    tuningSplit(X_train, Y_train)\n",
        "    \n",
        "    #\n",
        "    #   Continue with criterion = 'gini', splitter = 'best', min_samples_split = 2\n",
        "    #                     all of them are default values\n",
        "    print(\"5-Fold, depth = 5, criterion = 'gini', splitter = 'best, min_samples_split = 2\\n\")\n",
        "    tuningClassWeight(X_train, Y_train)\n",
        "\n",
        "    #\n",
        "    #   Continue with class_weight = None,   default\n",
        "    #\n",
        "    \n",
        "    clf = DecisionTreeClassifier(max_depth = 5, random_state = 0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    \n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"Accuracy: \", metrics.accuracy_score(Y_test, y_pred)*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soasxcXZCjhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningClassWeight(X_train, Y_train):\n",
        "    # No class weight\n",
        "    clf = DecisionTreeClassifier(max_depth = 5, random_state = 0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "    cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "    print(\"Class weight: None           Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    # Balanced class weight\n",
        "    clf = DecisionTreeClassifier(max_depth = 5, random_state = 0, class_weight ='balanced')\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "    cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "    print(\"Class weight: Balanced       Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHMjFVgH4Y7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningSplit(X_train, Y_train):\n",
        "    criterion = [\"gini\", \"entropy\"]\n",
        "    splitter = [\"best\", \"random\"]\n",
        "\n",
        "    for i in criterion:\n",
        "        for j in splitter:\n",
        "            clf = DecisionTreeClassifier(criterion = i, splitter = j, max_depth = 5, random_state = 0)\n",
        "            clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "            print(\"Criterion: \", i, \"   Splitter: \", j, \"   Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    for i in range(2, 10):\n",
        "        clf = DecisionTreeClassifier(max_depth = 5, min_samples_split = i, random_state = 0)\n",
        "        clf.fit(X_train, Y_train)\n",
        "\n",
        "        cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "        print(\"min_samples_split: \", i, \"   Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F92x5ZHNeunE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningDepth(X_train, Y_train, val):\n",
        "\n",
        "    max_depth_range = list(range(1, 10))\n",
        "    \n",
        "    for depth in max_depth_range:\n",
        "        if (val == 0):\n",
        "            clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "            clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "            print(\"Depth: \", depth, \" Accuracy: \",cv.mean()*100)\n",
        "\n",
        "        elif (val == 1):\n",
        "            clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "            clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "            print(\"Depth: \", depth, \" Accuracy: \",cv.mean()*100)\n",
        "\n",
        "        elif(val == 2):\n",
        "            x_train, x_test, y_train, y_test = randomOneHoldout(X_train, Y_train)\n",
        "\n",
        "            clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "            clf.fit(x_train, y_train)\n",
        "\n",
        "            score = clf.score(x_test, y_test)\n",
        "            print(\"Depth: \", depth, \" Accuracy: \", score*100)\n",
        "\n",
        "        elif(val == 3):\n",
        "            x_train, x_test, y_train, y_test = stratifiedOneHoldout(X_train, Y_train)\n",
        "\n",
        "            clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "            clf.fit(x_train, y_train)\n",
        "\n",
        "            score = clf.score(x_test, y_test)\n",
        "            print(\"Depth: \", depth, \" Accuracy: \", score*100)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid validation tech.\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGEz0duV_zJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayAccuracy(X, Y):\n",
        "    \n",
        "    NaiveBayes(X, Y)\n",
        "    #DecisionTree(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCG-PjOK0hpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zValues(df):\n",
        "    \n",
        "    cols = list(df.columns)\n",
        "    cols.remove('Index')\n",
        "\n",
        "    for col in cols:\n",
        "        col_zscore = col + '_zscore'\n",
        "        df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ch_JU38Fe7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outliers(df):  \n",
        "    return df.loc[(df._1_zscore > 2.5) | (df._2_zscore > 2.5) | (df._2_zscore > 2.5) | (df._3_zscore > 2.5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXU8_kQSH4qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dropOutliers(df):\n",
        "    df = df.drop([15, 24, 44, 117, 131])\n",
        "    return df "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azKxx12s6s63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subDatasets(df):\n",
        "    target0 = []\n",
        "    target1 = []\n",
        "    target2 = []\n",
        "    for row in df.itertuples():\n",
        "        if row.target == 0:\n",
        "            target0.append(row)\n",
        "            target0_df = pd.DataFrame(target0)\n",
        "        elif row.target == 1:\n",
        "            target1.append(row)\n",
        "            target1_df = pd.DataFrame(target1)\n",
        "        else:\n",
        "            target2.append(row)    \n",
        "            target2_df = pd.DataFrame(target2)  \n",
        "\n",
        "    dfs = [target0_df, target1_df, target2_df]  \n",
        "\n",
        "    for df in dfs:\n",
        "        df.drop(columns=['target'])\n",
        "    \n",
        "    return target0_df, target1_df, target2_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-z4_9i_223",
        "colab_type": "code",
        "outputId": "5e7a8a1b-5f41-4c8d-ef81-2883cf4b7294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  iris = datasets.load_iris()\n",
        "  \n",
        "  X = iris.data\n",
        "  Y = iris.target\n",
        "  \n",
        "  # L1 normalization\n",
        "  l1_norm = preprocessing.normalize(X, norm=\"l1\")\n",
        "  # Mean removal\n",
        "  mean_removal = preprocessing.scale(X)\n",
        "\n",
        "  #Displaying result according to each type of methods and regression model\n",
        "  #print(\"\\nRaw: \")\n",
        "  displayAccuracy(X,Y)\n",
        "  \n",
        "  print(\"\\nL1 Normalization: \")\n",
        "  displayAccuracy(l1_norm,Y)\n",
        "  '''\n",
        "  print(\"\\nMean Removal: \")\n",
        "  displayAccuracy(mean_removal,Y)'''\n",
        "\n",
        "  df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "  df['target'] = iris.target\n",
        "  pd.set_option('display.max_rows', df.shape[0]+1)\n",
        " \n",
        "  t0, t1, t2 = subDatasets(df)\n",
        "  \n",
        "  z0 = zValues(t0)\n",
        "  z1 = zValues(t1)\n",
        "  z2 = zValues(t2)\n",
        "  \n",
        "  out0 = outliers(z0)\n",
        "  out1 = outliers(z1)\n",
        "  out2 = outliers(z2)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "5-Fold\n",
            "Gaussian Naive Bayes Accuracy:  95.0\n",
            "Categorical Naive Bayes Accuracy:  93.33333333333333\n",
            "Bernoulli Naive Bayes Accuracy:  36.666666666666664\n",
            "Complement Naive Bayes Accuracy:  69.16666666666667\n",
            "Multinomial Naive Bayes Accuracy:  71.66666666666666\n",
            "\n",
            "10-Fold\n",
            "Gaussian Naive Bayes Accuracy:  94.99999999999999\n",
            "Categorical Naive Bayes Accuracy:  91.66666666666666\n",
            "Bernoulli Naive Bayes Accuracy:  36.66666666666667\n",
            "Complement Naive Bayes Accuracy:  69.16666666666667\n",
            "Multinomial Naive Bayes Accuracy:  70.83333333333334\n",
            "\n",
            "Random One Holdout\n",
            "Gaussian Naive Bayes Accuracy:  87.5\n",
            "Categorical Naive Bayes Accuracy:  87.5\n",
            "Bernoulli Naive Bayes Accuracy:  37.5\n",
            "Complement Naive Bayes Accuracy:  70.83333333333334\n",
            "Multinomial Naive Bayes Accuracy:  70.83333333333334\n",
            "\n",
            "Stratified One Holdout\n",
            "Gaussian Naive Bayes Accuracy:  91.66666666666666\n",
            "Categorical Naive Bayes Accuracy:  95.83333333333334\n",
            "Bernoulli Naive Bayes Accuracy:  37.5\n",
            "Complement Naive Bayes Accuracy:  70.83333333333334\n",
            "Multinomial Naive Bayes Accuracy:  70.83333333333334\n",
            "\n",
            "L1 Normalization: \n",
            "\n",
            "5-Fold\n",
            "Gaussian Naive Bayes Accuracy:  95.0\n",
            "Categorical Naive Bayes Accuracy:  36.666666666666664\n",
            "Bernoulli Naive Bayes Accuracy:  36.666666666666664\n",
            "Complement Naive Bayes Accuracy:  69.16666666666667\n",
            "Multinomial Naive Bayes Accuracy:  69.16666666666667\n",
            "\n",
            "10-Fold\n",
            "Gaussian Naive Bayes Accuracy:  95.83333333333333\n",
            "Categorical Naive Bayes Accuracy:  36.66666666666667\n",
            "Bernoulli Naive Bayes Accuracy:  36.66666666666667\n",
            "Complement Naive Bayes Accuracy:  69.16666666666667\n",
            "Multinomial Naive Bayes Accuracy:  69.16666666666667\n",
            "\n",
            "Random One Holdout\n",
            "Gaussian Naive Bayes Accuracy:  91.66666666666666\n",
            "Categorical Naive Bayes Accuracy:  37.5\n",
            "Bernoulli Naive Bayes Accuracy:  37.5\n",
            "Complement Naive Bayes Accuracy:  70.83333333333334\n",
            "Multinomial Naive Bayes Accuracy:  70.83333333333334\n",
            "\n",
            "Stratified One Holdout\n",
            "Gaussian Naive Bayes Accuracy:  100.0\n",
            "Categorical Naive Bayes Accuracy:  37.5\n",
            "Bernoulli Naive Bayes Accuracy:  37.5\n",
            "Complement Naive Bayes Accuracy:  70.83333333333334\n",
            "Multinomial Naive Bayes Accuracy:  70.83333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgY0d9DaKApK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKU8YsPG4y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj7u3ZNzG6iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSUfJfMqHKmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df = dropOutliers(df)\n",
        "#df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfv_qSw6Wb-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#iris = df.to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}