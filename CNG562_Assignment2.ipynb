{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562-Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisanuro/CNG562-Assignment-2/blob/master/CNG562_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "738YGK5FqWmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics, datasets, preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, ComplementNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlXDAHx2Gt_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataVisualizaion(iris):\n",
        "    x_index = 0\n",
        "    y_index = 1\n",
        "\n",
        "    formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
        "    \n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)\n",
        "    plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
        "    plt.xlabel(iris.feature_names[x_index])\n",
        "    plt.ylabel(iris.feature_names[y_index])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Feo4-PRyTbvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def threeDVisualization(X, y):\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    fig = plt.figure(1, figsize=(16, 9))\n",
        "    ax = Axes3D(fig, elev=-150, azim=110)\n",
        "    X_reduced = PCA(n_components=3).fit_transform(X_scaled)\n",
        "    ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y, cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
        "    ax.set_title(\"First three PCA directions\")\n",
        "    ax.set_xlabel(\"1st eigenvector\")\n",
        "    ax.w_xaxis.set_ticklabels([])\n",
        "    ax.set_ylabel(\"2nd eigenvector\")\n",
        "    ax.w_yaxis.set_ticklabels([])\n",
        "    ax.set_zlabel(\"3rd eigenvector\")\n",
        "    ax.w_zaxis.set_ticklabels([])\n",
        "\n",
        "    plt.show()\n",
        "    print(\"The number of features in the new subspace is \", X_reduced.shape[1])\n",
        "\n",
        "    return X_reduced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skeQ9JV9_rlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomOneHoldout(X_train, Y_train):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjpybV6_v7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratifiedOneHoldout(X_train, Y_train):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGpMxh6aK-FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NaiveBayes(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=9)\n",
        "    '''\n",
        "    # Gaussian Naive Bayes\n",
        "    gaussian = GaussianNB()\n",
        "    NaiveBayesValidations(X_train, Y_train, gaussian)\n",
        "\n",
        "    y_pred = gaussian.predict(X_test)\n",
        "    print(\"Accuracy - unseen data: \", metrics.accuracy_score(Y_test, y_pred)*100)\n",
        "    \n",
        "    fourError(X, Y, gaussian)\n",
        "    \n",
        "    \n",
        "    # Multinomial Naive Bayes\n",
        "    multinomial = MultinomialNB(fit_prior=True)\n",
        "    NaiveBayesValidations(X_train, Y_train, multinomial)\n",
        "\n",
        "    y_pred = multinomial.predict(X_test)\n",
        "    print(\"Accuracy - unseen data: \", metrics.accuracy_score(Y_test, y_pred)*100)\n",
        "\n",
        "    fourError(X, Y, multinomial)\n",
        "    '''\n",
        "    \n",
        "    # Bernoulli Naive Bayes\n",
        "    \n",
        "    bernoulli = BernoulliNB(binarize = 1.75)\n",
        "    bernoulli.fit(X_train, Y_train)\n",
        "    #NaiveBayesValidations(X_train, Y_train, bernoulli)\n",
        "\n",
        "    \n",
        "    y_pred = bernoulli.predict(X_test)\n",
        "    print(\"Accuracy - unseen data: \", metrics.accuracy_score(Y_test, y_pred)*100)\n",
        "\n",
        "    fourError(X, Y, bernoulli)\n",
        "    \n",
        "    #BernoulliBinarize(X_train, Y_train)\n",
        "    \n",
        "    '''\n",
        "    # Complement Naive Bayes\n",
        "    \n",
        "    complement = ComplementNB()\n",
        "    NaiveBayesValidations(X_train, Y_train, complement)\n",
        "\n",
        "    y_pred = complement.predict(X_test)\n",
        "    print(\"Accuracy - unseen data: \", metrics.accuracy_score(Y_test, y_pred)*100)\n",
        "\n",
        "    fourError(X, Y, complement)\n",
        "    \n",
        "    #complementTuning(X_train, Y_train)\n",
        "    \n",
        "    # Categorical Naive Bayes\n",
        "    categorical = CategoricalNB(fit_prior = False)\n",
        "    NaiveBayesValidations(X_train, Y_train, categorical)                \n",
        "    '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y2DlvqILDQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complementTuning(X_train, Y_train):\n",
        "    fit_prior = [True, False]\n",
        "    norm = [True, False]\n",
        "\n",
        "    for i in fit_prior:\n",
        "        for j in norm:\n",
        "            model = ComplementNB(fit_prior = i, norm = j)\n",
        "\n",
        "            cv = cross_val_score(model, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "\n",
        "            print(\"fit_prior = \", i, \"   norm = \", j, \"   Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRiagr3DLGFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BernoulliBinarize(X_train, Y_train):\n",
        "    binarize = [0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3]\n",
        "\n",
        "    for i in binarize:\n",
        "\n",
        "        model = BernoulliNB(binarize = i)\n",
        "        cv = cross_val_score(model, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "        print(\"Binarize = \", i, \"    Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOwVmd3LJkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NaiveBayesValidations(X_train, Y_train, model):\n",
        "    print(\"\\n\" + str(model).split('N')[0] + \" Naive Bayes Accuracy\\n\")\n",
        "    # 5-Fold\n",
        "    cv = cross_val_score(model, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "    print(\"5-Fold: \", cv.mean()*100)\n",
        "    \n",
        "    # 10-Fold\n",
        "    cv = cross_val_score(model, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "\n",
        "    print(\"10-Fold: \", cv.mean()*100)\n",
        "\n",
        "    # Random One Holdout\n",
        "    x_train, x_test, y_train, y_test = randomOneHoldout(X_train, Y_train)\n",
        "    \n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    print(\"Random One Holdout: \", metrics.accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "    # Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test = stratifiedOneHoldout(X_train, Y_train)\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    print(\"Stratified One Holdout: \", metrics.accuracy_score(y_test, y_pred)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwb5WKRtLNGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTree(X, Y):\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "    \n",
        "    # 5-Fold\n",
        "    print(\"\\n5-Fold: \")\n",
        "    tuningDepth(X_train, Y_train, 0)\n",
        "\n",
        "    # 10-Fold\n",
        "    print(\"\\n10-Fold: \")\n",
        "    tuningDepth(X_train, Y_train, 1)\n",
        "\n",
        "    # Random One Holdout\n",
        "    print(\"\\nRandom One Holdout: \")   \n",
        "    tuningDepth(X_train, Y_train, 2)\n",
        "  \n",
        "    # Stratified One Holdout\n",
        "    print(\"\\nStratified One Holdout: \")\n",
        "    tuningDepth(X_train, Y_train, 3)\n",
        "    \n",
        "    #\n",
        "    #   Continue with 10-Fold, Depth = 3\n",
        "    #\n",
        "    \n",
        "    print(\"5-Fold, Depth=5\\n\")\n",
        "    tuningSplit(X_train, Y_train)\n",
        "    \n",
        "    #\n",
        "    #   Continue with criterion = 'gini', splitter = 'best', min_samples_split = 2\n",
        "    #                     all of them are default values\n",
        "    print(\"5-Fold, depth = 5, criterion = 'gini', splitter = 'best, min_samples_split = 2\\n\")\n",
        "    tuningClassWeight(X_train, Y_train)\n",
        "\n",
        "    #\n",
        "    #   Continue with class_weight = None,   default\n",
        "    #\n",
        "    \n",
        "    clf = DecisionTreeClassifier(max_depth = 3)\n",
        "    '''\n",
        "    clf.fit(X_train, Y_train)\n",
        "    \n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"Accuracy: \", metrics.accuracy_score(Y_test, y_pred)*100)\n",
        "    '''\n",
        "    fourError(X, Y, clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UicrTaLkLRSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningClassWeight(X_train, Y_train):\n",
        "    # No class weight\n",
        "    clf = DecisionTreeClassifier(max_depth = 3, random_state = 0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "    cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "    print(\"Class weight: None           Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    # Balanced class weight\n",
        "    clf = DecisionTreeClassifier(max_depth = 3, random_state = 0, class_weight ='balanced')\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "    cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "    print(\"Class weight: Balanced       Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2S6OKkLUrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningSplit(X_train, Y_train):\n",
        "    criterion = [\"gini\", \"entropy\"]\n",
        "    splitter = [\"best\", \"random\"]\n",
        "\n",
        "    for i in criterion:\n",
        "        for j in splitter:\n",
        "            clf = DecisionTreeClassifier(criterion = i, splitter = j, max_depth = 3, random_state = 0)\n",
        "            clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "            print(\"Criterion: \", i, \"   Splitter: \", j, \"   Accuracy: \", cv.mean()*100)\n",
        "\n",
        "    for i in range(2, 10):\n",
        "        clf = DecisionTreeClassifier(max_depth = 3, min_samples_split = i, random_state = 0)\n",
        "        clf.fit(X_train, Y_train)\n",
        "\n",
        "        cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "        print(\"min_samples_split: \", i, \"   Accuracy: \", cv.mean()*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JhAsgk2LZAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningDepth(X_train, Y_train, val):\n",
        "\n",
        "    max_depth_range = list(range(1, 10))\n",
        "    max_depth_range.append(str(\"None\"))\n",
        "    \n",
        "\n",
        "    for depth in max_depth_range:\n",
        "        if (val == 0):\n",
        "            if(depth == \"None\"):\n",
        "                clf = DecisionTreeClassifier(random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "            else:               \n",
        "                clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "            accuracy = cv.mean()*100\n",
        "            print(\"Depth: \", depth, \" Accuracy: \", accuracy)\n",
        "            \n",
        "        elif (val == 1):\n",
        "            if(depth == \"None\"):\n",
        "                clf = DecisionTreeClassifier(random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "            else:  \n",
        "                clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "\n",
        "            cv = cross_val_score(clf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "            accuracy = cv.mean()*100\n",
        "            print(\"Depth: \", depth, \" Accuracy: \",accuracy)\n",
        "            \n",
        "        elif(val == 2):            \n",
        "            x_train, x_test, y_train, y_test = randomOneHoldout(X_train, Y_train)\n",
        "\n",
        "            if(depth == \"None\"):\n",
        "                clf = DecisionTreeClassifier(random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "            else:  \n",
        "                clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "                clf.fit(x_train, y_train)\n",
        "\n",
        "            accuracy = clf.score(x_test, y_test)*100\n",
        "            print(\"Depth: \", depth, \" Accuracy: \", accuracy)\n",
        "            \n",
        "        elif(val == 3):\n",
        "            x_train, x_test, y_train, y_test = stratifiedOneHoldout(X_train, Y_train)\n",
        "\n",
        "            if(depth == \"None\"):\n",
        "                clf = DecisionTreeClassifier(random_state = 0)\n",
        "                clf.fit(X_train, Y_train)\n",
        "            else:  \n",
        "                clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
        "                clf.fit(x_train, y_train)\n",
        "\n",
        "            accuracy = clf.score(x_test, y_test)*100\n",
        "            print(\"Depth: \", depth, \" Accuracy: \", accuracy)\n",
        "            \n",
        "        else:\n",
        "            print(\"Invalid validation tech.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BVBws30S0w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNN(k: int, metric: str, X_train, Y_train):\n",
        "  \n",
        "    #Model\n",
        "    if metric == \"mahalanobis\":\n",
        "      knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric=metric, algorithm=\"brute\", metric_params={'V': np.cov(X_train)})\n",
        "    else:\n",
        "      knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric=metric)\n",
        "\n",
        "    #5-Fold\n",
        "    cv_result_knn_5 = cross_val_score(knn, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "  \n",
        "    #10-Fold\n",
        "    cv_result_knn_10 = cross_val_score(knn, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "  \n",
        "    #Random One Holdout\n",
        "    x_train, x_test, y_train, y_test_random = randomOneHoldout(X_train, Y_train)\n",
        "    knn.fit(x_train, y_train)\n",
        "\n",
        "    y_pred_knn_random = knn.predict(x_test)\n",
        "  \n",
        "    #Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test_stratified = stratifiedOneHoldout(X_train, Y_train)\n",
        "    knn.fit(x_train, y_train)\n",
        "    y_pred_knn_stratified = knn.predict(x_test)\n",
        "\n",
        "    print(\"5 Fold\")\n",
        "    print(\"KNN Accuracy: \", cv_result_knn_5.mean())\n",
        "  \n",
        "    print(\"10 Fold\")\n",
        "    print(\"KNN Accuracy: \", cv_result_knn_10.mean())\n",
        "\n",
        "    print(\"Random One Hold Out\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(y_test_random, y_pred_knn_random))\n",
        "  \n",
        "    print(\"Stratified One Hold Out Fold\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(y_test_stratified, y_pred_knn_stratified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k3k_9eDQ6t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm(X_train, Y_train, kernel, weight, gamma):\n",
        "\n",
        "    svm = SVC(C=1, kernel=kernel, degree=3, gamma=gamma, coef0=0.0, shrinking=True, \n",
        "          probability=False, tol=0.001, cache_size=200, class_weight=weight,\n",
        "          max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
        "\n",
        "    #5-Fold\n",
        "    cv_result_svm_5 = cross_val_score(svm, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "  \n",
        "    #10-Fold\n",
        "    cv_result_svm_10 = cross_val_score(svm, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "  \n",
        "    #Random One Holdout\n",
        "    x_train, x_test, y_train, y_test_random = randomOneHoldout(X_train, Y_train)\n",
        "    svm.fit(x_train, y_train)\n",
        "    y_pred_svm_random = svm.predict(x_test)\n",
        "  \n",
        "    #Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test_stratified = stratifiedOneHoldout(X_train, Y_train)\n",
        "    svm.fit(x_train, y_train)\n",
        "    y_pred_svm_stratified = svm.predict(x_test)\n",
        "\n",
        "    print(\"5 Fold\")\n",
        "    print(\"SVM Accuracy: \", cv_result_svm_5.mean())\n",
        "  \n",
        "    #print(\"10 Fold\")\n",
        "    #print(\"SVM Accuracy: \", cv_result_svm_10.mean())\n",
        "\n",
        "    #print(\"Random One Hold Out\")\n",
        "    #print(\"SVM Accuracy: \", 1 - metrics.mean_squared_error(y_test_random, y_pred_svm_random))\n",
        "  \n",
        "    #print(\"Stratified One Hold Out Fold\")\n",
        "    #print(\"SVM Accuracy: \", 1 - metrics.mean_squared_error(y_test_stratified, y_pred_svm_stratified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaldHpB1LjQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zValues(df):\n",
        "    \n",
        "    cols = list(df.columns)\n",
        "    cols.remove('Index')\n",
        "\n",
        "    for col in cols:\n",
        "        col_zscore = col + '_zscore'\n",
        "        df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgd_SgcOLlY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zValues(df):\n",
        "    \n",
        "    cols = list(df.columns)\n",
        "    cols.remove('Index')\n",
        "\n",
        "    for col in cols:\n",
        "        col_zscore = col + '_zscore'\n",
        "        df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-bInRUkY-PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AdaBoost(model, n_estimators, learning_rate, X_train, Y_train, X_test, Y_test):\n",
        "    clf = AdaBoostClassifier(base_estimator = model, n_estimators= n_estimators, learning_rate=learning_rate, random_state=0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    clf.predict(X_test)\n",
        "    return clf.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zD9wkpoZuj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GradientBoost(n_estimators, learning_rate, X_train, Y_train, X_test, Y_test):\n",
        "    clf = GradientBoostingClassifier(n_estimators= n_estimators, learning_rate=learning_rate, random_state=0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    clf.predict(X_test)\n",
        "    return clf.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ZtQKDStF5Sm",
        "colab": {}
      },
      "source": [
        "def fourError(X, Y, model):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0, stratify=Y)\n",
        "    \n",
        "    Train_x, TrainDev_x, Train_y, TrainDev_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        "    Dev_x, Test_x, Dev_y, Test_y = train_test_split(X_test, Y_test, test_size=0.5, random_state=0, stratify=Y_test)\n",
        "\n",
        "    model.fit(Train_x, Train_y)\n",
        "\n",
        "    y_true, trainDev_pred = TrainDev_y, model.predict(TrainDev_x)\n",
        "\n",
        "    print(\"Train-Train Dev,   e1:\", metrics.mean_squared_error(TrainDev_y, trainDev_pred),\"\\n\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(TrainDev_y, trainDev_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, trainDev_pred))\n",
        "\n",
        "    y_true, dev_pred = Dev_y, model.predict(Dev_x)\n",
        "    print(\"Train-Dev,   e2\", metrics.mean_squared_error(Dev_y, dev_pred),\"\\n\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(Dev_y, dev_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, dev_pred))\n",
        "\n",
        "    y_true, test_pred = Test_y, model.predict(Test_x)\n",
        "    print(\"Train-Test,   e3: \", metrics.mean_squared_error(Test_y, test_pred),\"\\n\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(Test_y, test_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, test_pred))\n",
        "\n",
        "    y_true, devTest_pred = Y_test, model.predict(X_test)\n",
        "    print(\"Train-(Dev+Test),   e4: \", metrics.mean_squared_error(Y_test, devTest_pred),\"\\n\")\n",
        "    print(\"KNN Accuracy: \", 1 - metrics.mean_squared_error(Y_test, devTest_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, devTest_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGEz0duV_zJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayAccuracy(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "    k = [3, 5, 7, 9, 11]\n",
        "    metric = [\"euclidean\", \"manhattan\", \"chebyshev\", \"mahalanobis\", \"minkowski\", \"wminkowski\", \"seuclidean\"]\n",
        "    kernel = [\"linear\", \"rbf\"]\n",
        "    weight = [None, \"balanced\"]\n",
        "    gamma = [\"auto\", \"scale\"]\n",
        "\n",
        "    for i in k:\n",
        "      for j in metric:\n",
        "          if j != \"wminkowski\" and j != \"seuclidean\":\n",
        "            print(\"K: {} - Metric: {}\".format(i, j))\n",
        "            kNN(i, j, X_train, Y_train)\n",
        "          print()\n",
        "    \n",
        "    for i in kernel:\n",
        "        for j in weight:\n",
        "            for k in gamma:\n",
        "                if i != \"linear\":\n",
        "                    print(\"Kernel: {} - Weight: {} - Gamma: {}\".format(str(i), j, k))\n",
        "                    svm(X_train, Y_train, i, j, k)\n",
        "                else:\n",
        "                    print(\"Kernel: {} - Weight: {} - Gamma: {}\".format(str(i), j, \"auto\"))\n",
        "                    svm(X_train, Y_train, i, j, k)\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c_Vbu1AW3LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subDatasets(df):\n",
        "    target0 = []\n",
        "    target1 = []\n",
        "    target2 = []\n",
        "    for row in df.itertuples():\n",
        "        if row.target == 0:\n",
        "            target0.append(row)\n",
        "            target0_df = pd.DataFrame(target0)\n",
        "        elif row.target == 1:\n",
        "            target1.append(row)\n",
        "            target1_df = pd.DataFrame(target1)\n",
        "        else:\n",
        "            target2.append(row)    \n",
        "            target2_df = pd.DataFrame(target2)  \n",
        "\n",
        "    dfs = [target0_df, target1_df, target2_df]  \n",
        "\n",
        "    for df in dfs:\n",
        "        df.drop(columns=['target'])\n",
        "    \n",
        "    return target0_df, target1_df, target2_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-z4_9i_223",
        "colab_type": "code",
        "outputId": "e4e05db9-ebec-408b-d16c-e7688c892ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  iris = datasets.load_iris()\n",
        "  X = iris.data\n",
        "  Y = iris.target\n",
        "  \n",
        "  #threeDVisualization(iris.data[:, :], Y)\n",
        "  \n",
        "  # Z-Score\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X)\n",
        "  z_score = scaler.transform(X)\n",
        "\n",
        "  #Displaying result according to each type of methods and regression model\n",
        "  print(\"\\nRaw: \")\n",
        "  displayAccuracy(X,Y)\n",
        "  #print(\"\\nZ-Score: \")\n",
        "  #displayAccuracy(z_score,Y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Raw: \n",
            "K: 3 - Metric: euclidean\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9428571428571428\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9427272727272727\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 3 - Metric: manhattan\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9428571428571428\n",
            "10 Fold\n",
            "KNN Accuracy:  0.941818181818182\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 3 - Metric: chebyshev\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9518181818181818\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 3 - Metric: mahalanobis\n",
            "5 Fold\n",
            "KNN Accuracy:  0.8285714285714285\n",
            "10 Fold\n",
            "KNN Accuracy:  0.8981818181818182\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 3 - Metric: minkowski\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9428571428571428\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9427272727272727\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "\n",
            "\n",
            "K: 5 - Metric: euclidean\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9509090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 5 - Metric: manhattan\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9428571428571428\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9509090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 5 - Metric: chebyshev\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9714285714285715\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9709090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 5 - Metric: mahalanobis\n",
            "5 Fold\n",
            "KNN Accuracy:  0.8476190476190476\n",
            "10 Fold\n",
            "KNN Accuracy:  0.8790909090909091\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "\n",
            "K: 5 - Metric: minkowski\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9509090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "\n",
            "\n",
            "K: 7 - Metric: euclidean\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 7 - Metric: manhattan\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9428571428571428\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 7 - Metric: chebyshev\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9709090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 7 - Metric: mahalanobis\n",
            "5 Fold\n",
            "KNN Accuracy:  0.8857142857142858\n",
            "10 Fold\n",
            "KNN Accuracy:  0.889090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 7 - Metric: minkowski\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "\n",
            "\n",
            "K: 9 - Metric: euclidean\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 9 - Metric: manhattan\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 9 - Metric: chebyshev\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9523809523809523\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 9 - Metric: mahalanobis\n",
            "5 Fold\n",
            "KNN Accuracy:  0.8857142857142858\n",
            "10 Fold\n",
            "KNN Accuracy:  0.8800000000000001\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 9 - Metric: minkowski\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "\n",
            "\n",
            "K: 11 - Metric: euclidean\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 11 - Metric: manhattan\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 11 - Metric: chebyshev\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9427272727272727\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 11 - Metric: mahalanobis\n",
            "5 Fold\n",
            "KNN Accuracy:  0.8666666666666666\n",
            "10 Fold\n",
            "KNN Accuracy:  0.8700000000000001\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "K: 11 - Metric: minkowski\n",
            "5 Fold\n",
            "KNN Accuracy:  0.9619047619047618\n",
            "10 Fold\n",
            "KNN Accuracy:  0.9609090909090909\n",
            "Random One Hold Out\n",
            "KNN Accuracy:  1.0\n",
            "Stratified One Hold Out Fold\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "\n",
            "\n",
            "Kernel: linear - Weight: None - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9714285714285715\n",
            "Kernel: linear - Weight: None - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9714285714285715\n",
            "Kernel: linear - Weight: balanced - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.980952380952381\n",
            "Kernel: linear - Weight: balanced - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.980952380952381\n",
            "\n",
            "Kernel: rbf - Weight: None - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9714285714285713\n",
            "Kernel: rbf - Weight: None - Gamma: scale\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9523809523809523\n",
            "Kernel: rbf - Weight: balanced - Gamma: auto\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9714285714285713\n",
            "Kernel: rbf - Weight: balanced - Gamma: scale\n",
            "5 Fold\n",
            "SVM Accuracy:  0.9619047619047618\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yab09cbEcfMI",
        "colab_type": "code",
        "outputId": "b3e7cb03-2efb-45bd-a35a-db491a216548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    svm = SVC(C=1, degree=3, gamma=\"scale\", coef0=0.0, shrinking=True, \n",
        "          probability=True, tol=0.001, cache_size=200, class_weight=\"balanced\",\n",
        "          max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "    \n",
        "    #svm.fit(X_train, Y_train)\n",
        "    #y_true, y_pred = Y_test, svm.predict(X_test)\n",
        "    #print(\"SVM Accuracy: \", 1 - metrics.mean_squared_error(Y_test, y_pred))\n",
        "\n",
        "    fourError(X, Y, svm)\n",
        "\n",
        "    #AdaBoost(svm, 100, 1, X_train, Y_train, X_test, Y_test)\n",
        "    #GradientBoost(100, 1, X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-Train Dev,   e1: 0.09523809523809523 \n",
            "\n",
            "KNN Accuracy:  0.9047619047619048\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.78      1.00      0.88         7\n",
            "           2       1.00      0.71      0.83         7\n",
            "\n",
            "    accuracy                           0.90        21\n",
            "   macro avg       0.93      0.90      0.90        21\n",
            "weighted avg       0.93      0.90      0.90        21\n",
            "\n",
            "Train-Dev,   e2 0.0 \n",
            "\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00         7\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        22\n",
            "   macro avg       1.00      1.00      1.00        22\n",
            "weighted avg       1.00      1.00      1.00        22\n",
            "\n",
            "Train-Test,   e3:  0.0 \n",
            "\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        23\n",
            "   macro avg       1.00      1.00      1.00        23\n",
            "weighted avg       1.00      1.00      1.00        23\n",
            "\n",
            "Train-(Dev+Test),   e4:  0.0 \n",
            "\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        15\n",
            "           2       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KYMRBV_y-P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbf8bb6a-e32c-4754-a720-9039ee7a4a90"
      },
      "source": [
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=7, weights='uniform', metric=\"chebyshev\")\n",
        "    #knn.fit(X_train, Y_train)\n",
        "\n",
        "    #y_true, y_pred = Y_test, knn.predict(X_test)\n",
        "    fourError(X, Y, knn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-Train Dev,   e1: 0.19047619047619047 \n",
            "\n",
            "KNN Accuracy:  0.8095238095238095\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.71      0.71      0.71         7\n",
            "           2       0.71      0.71      0.71         7\n",
            "\n",
            "    accuracy                           0.81        21\n",
            "   macro avg       0.81      0.81      0.81        21\n",
            "weighted avg       0.81      0.81      0.81        21\n",
            "\n",
            "Train-Dev,   e2 0.045454545454545456 \n",
            "\n",
            "KNN Accuracy:  0.9545454545454546\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.88      1.00      0.93         7\n",
            "           2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.96      0.96        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n",
            "Train-Test,   e3:  0.0 \n",
            "\n",
            "KNN Accuracy:  1.0\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        23\n",
            "   macro avg       1.00      1.00      1.00        23\n",
            "weighted avg       1.00      1.00      1.00        23\n",
            "\n",
            "Train-(Dev+Test),   e4:  0.022222222222222223 \n",
            "\n",
            "KNN Accuracy:  0.9777777777777777\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.94      1.00      0.97        15\n",
            "           2       1.00      0.93      0.97        15\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOgFpxAprPQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
        "#Worst model\n",
        "complement = ComplementNB()\n",
        "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1 ,2 ,3 ,4, 5]\n",
        "\n",
        "result_ada_1 = []\n",
        "result_gradient_1 = []\n",
        "for i in learning_rate: #i -> Learning Rate\n",
        "    x = []\n",
        "    y = []\n",
        "    for j in range(50, 150): #j -> N estimators\n",
        "        x.append(AdaBoost(complement, j, i, X_train, Y_train, X_test, Y_test))\n",
        "        y.append(GradientBoost(j, i, X_train, Y_train, X_test, Y_test))\n",
        "    result_ada_1.append(x)\n",
        "    result_gradient_1.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYuojo9EKjFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "#best model\n",
        "clf = DecisionTreeClassifier(max_depth = 3)\n",
        "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1 ,2 ,3 ,4, 5]\n",
        "\n",
        "result_ada_2 = []\n",
        "result_gradient_2 = []\n",
        "for i in learning_rate: #i -> Learning Rate\n",
        "    x = []\n",
        "    y = []\n",
        "    for j in range(50, 150): #j -> N estimators\n",
        "        x.append(AdaBoost(clf, j, i, X_train, Y_train, X_test, Y_test))\n",
        "        y.append(GradientBoost(j, i, X_train, Y_train, X_test, Y_test))\n",
        "    result_ada_2.append(x)\n",
        "    result_gradient_2.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjzi8CsaNu2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251f6e9b-f97a-42f9-f88c-8ee3f857c446"
      },
      "source": [
        "from pandas.tools.plotting import parallel_coordinates\n",
        "# Perform parallel coordinate plot\n",
        "parallel_coordinates(result_ada_1, 'Class')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a58f637404fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparallel_coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Perform parallel coordinate plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparallel_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_ada_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.tools'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQvMoKEPSjaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "57b18fc4-347b-4582-f14e-f814af7e0f42"
      },
      "source": [
        "parallel_coordinates(result_ada_2, 'Class')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-26c5f3e50f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparallel_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_ada_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'parallel_coordinates' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxT-ikW4VMTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "548581cc-453b-4d2c-f357-6b75e8e12896"
      },
      "source": [
        "parallel_coordinates(result_gradient_1, 'Class')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2cf6cae8e388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparallel_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_gradient_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'parallel_coordinates' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnnzeXslVPWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parallel_coordinates(result_gradient_2, 'Class')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}